{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl004KXr4N+debrmx5D5NM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajit93/open-university-video/blob/main/open_university_video_renderer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf *.wav *.png *.mp4 *.txt *.srt *.svg\n",
        "print(\"Workspace cleaned\")\n"
      ],
      "metadata": {
        "id": "Z1qhuVunoUjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PHONEMIZER_ESPEAK_PATH\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n",
        "os.environ[\"ESPEAK_PATH\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n",
        "print(\"eSpeak configured\")\n"
      ],
      "metadata": {
        "id": "AIP-GB36bj3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.api import TTS\n",
        "import random\n",
        "\n",
        "tts = TTS(model_name=\"tts_models/en/vctk/vits\", progress_bar=False, gpu=False)\n",
        "VOICE_POOL = [\"p225\",\"p226\",\"p227\",\"p228\"]\n",
        "\n",
        "def generate_dynamic_voice(text, out_file):\n",
        "    speaker = random.choice(VOICE_POOL)\n",
        "    text = text.replace(\".\", \"... \")\n",
        "    tts.tts_to_file(text=text, file_path=out_file, speaker=speaker)\n",
        "\n",
        "print(\"Dynamic TTS engine ready\")\n"
      ],
      "metadata": {
        "id": "Oy7LM580vGXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "slide_plan = json.loads(Path(\"slide_plan.json\").read_text())\n",
        "audio_map  = json.loads(Path(\"slide_audio_map.json\").read_text())\n",
        "\n",
        "assert len(slide_plan[\"slides\"]) == len(audio_map)\n",
        "print(\"Slides loaded:\", len(slide_plan[\"slides\"]))\n"
      ],
      "metadata": {
        "id": "9bcKXrw_aOIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def detect_energy_curve(audio_file):\n",
        "    y, sr = librosa.load(audio_file, sr=None)\n",
        "    energy = librosa.feature.rms(y=y)[0]\n",
        "    return np.mean(energy)\n",
        "\n",
        "def adaptive_chunk_duration(audio_file):\n",
        "    energy = detect_energy_curve(audio_file)\n",
        "    if energy > 0.08:\n",
        "        return 3\n",
        "    elif energy > 0.05:\n",
        "        return 4\n",
        "    else:\n",
        "        return 5\n"
      ],
      "metadata": {
        "id": "3eoZTnmIh0BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMPORTANT_WORDS = [\n",
        "    \"money\",\"power\",\"rich\",\"elite\",\"secret\",\"danger\",\n",
        "    \"control\",\"future\",\"mistake\",\"warning\",\"truth\",\n",
        "    \"hidden\",\"win\",\"lose\",\"status\",\"psychology\"\n",
        "]\n",
        "\n",
        "def word_style(word):\n",
        "    if word.lower() in IMPORTANT_WORDS:\n",
        "        return {\"color\":\"#FFD700\",\"scale\":1.3}\n",
        "    return {\"color\":\"white\",\"scale\":1.0}\n"
      ],
      "metadata": {
        "id": "MQr_f08_cTyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "voice_files = []\n",
        "\n",
        "for item in audio_map:\n",
        "    sid  = item[\"slide_id\"]\n",
        "    text = item[\"spoken_text\"]\n",
        "\n",
        "    raw   = f\"raw_{sid}.wav\"\n",
        "    final = f\"voice_{sid}.wav\"\n",
        "\n",
        "    generate_dynamic_voice(text, raw)\n",
        "\n",
        "    speed = random.uniform(0.95,1.1)\n",
        "\n",
        "    subprocess.run([\n",
        "        \"ffmpeg\",\"-y\",\n",
        "        \"-i\",raw,\n",
        "        \"-filter:a\",f\"atempo={speed}\",\n",
        "        \"-ar\",\"22050\",\n",
        "        \"-ac\",\"1\",\n",
        "        final\n",
        "    ],check=True)\n",
        "\n",
        "    voice_files.append(final)\n",
        "\n",
        "print(\"Voice files ready\")\n"
      ],
      "metadata": {
        "id": "F6RzaOasn6Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import AudioFileClip\n",
        "\n",
        "def emotional_music(audio_file):\n",
        "    energy = detect_energy_curve(audio_file)\n",
        "    if energy > 0.08:\n",
        "        volume = 0.25\n",
        "    else:\n",
        "        volume = 0.15\n",
        "    return volume\n"
      ],
      "metadata": {
        "id": "15oEzKdfn-cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoClip\n",
        "import numpy as np\n",
        "\n",
        "W,H = 1280,720\n",
        "\n",
        "def zoom_background(duration):\n",
        "    def make_frame(t):\n",
        "        img = np.zeros((H,W,3),dtype=np.uint8)\n",
        "        base = int(40 + (t*30)%100)\n",
        "        img[:,:,0] = base\n",
        "        img[:,:,1] = 40\n",
        "        img[:,:,2] = 255-base\n",
        "        return img\n",
        "    clip = VideoClip(make_frame,duration=duration)\n",
        "    return clip.resize(lambda t: 1+0.03*t)\n"
      ],
      "metadata": {
        "id": "_VfXfcSI74H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import TextClip\n",
        "\n",
        "def animated_counter(start, end, duration):\n",
        "    def make_text(t):\n",
        "        value = int(start + (end-start)*(t/duration))\n",
        "        return TextClip(str(value),\n",
        "                        fontsize=120,\n",
        "                        color=\"yellow\",\n",
        "                        font=\"DejaVu-Sans-Bold\")\n",
        "    return VideoClip(lambda t: make_text(t).get_frame(0),\n",
        "                     duration=duration)\n"
      ],
      "metadata": {
        "id": "l7mn1wJZCLS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infographic_bar(value, duration):\n",
        "    from moviepy.editor import VideoClip\n",
        "    def make_frame(t):\n",
        "        img = np.zeros((H,W,3),dtype=np.uint8)\n",
        "        width = int((t/duration)*W*value)\n",
        "        img[H//2-20:H//2+20,0:width] = (255,200,0)\n",
        "        return img\n",
        "    return VideoClip(make_frame,duration=duration)\n"
      ],
      "metadata": {
        "id": "srDikdfGCQ6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def moving_arrow(duration):\n",
        "    def make_frame(t):\n",
        "        img = np.zeros((H,W,3),dtype=np.uint8)\n",
        "        x = int((t/duration)*W)\n",
        "        img[H//2:H//2+10,x:x+100] = (255,0,0)\n",
        "        return img\n",
        "    return VideoClip(make_frame,duration=duration)\n"
      ],
      "metadata": {
        "id": "UgzVdNhqn9Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import *\n",
        "import math\n",
        "\n",
        "def kinetic_text_layer(text,duration):\n",
        "    words = text.split()\n",
        "    clips=[]\n",
        "    per = max(0.3,duration/len(words))\n",
        "    t_cursor=0\n",
        "\n",
        "    for w in words:\n",
        "        style = word_style(w)\n",
        "        clip=(TextClip(w,\n",
        "                       fontsize=90,\n",
        "                       font=\"DejaVu-Sans-Bold\",\n",
        "                       color=style[\"color\"])\n",
        "              .set_start(t_cursor)\n",
        "              .set_duration(per)\n",
        "              .resize(lambda t: style[\"scale\"] + 0.2*math.sin(t*8))\n",
        "              .set_position((\"center\",\"center\")))\n",
        "\n",
        "        clips.append(clip)\n",
        "        t_cursor+=per\n",
        "\n",
        "    return CompositeVideoClip(clips).set_duration(duration)\n"
      ],
      "metadata": {
        "id": "fx4nM9XlCZSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments=[]\n",
        "import math\n",
        "\n",
        "for slide in slide_plan[\"slides\"]:\n",
        "    sid  = slide[\"slide_id\"]\n",
        "    text = slide.get(\"right_panel_gist\",\"\")\n",
        "    audio_file=f\"voice_{sid}.wav\"\n",
        "\n",
        "    audio= AudioFileClip(audio_file)\n",
        "    total=audio.duration\n",
        "    chunk=adaptive_chunk_duration(audio_file)\n",
        "    parts=math.ceil(total/chunk)\n",
        "\n",
        "    for i in range(parts):\n",
        "        start=i*chunk\n",
        "        end=min((i+1)*chunk,total)\n",
        "        dur=end-start\n",
        "\n",
        "        bg = zoom_background(dur)\n",
        "        txt = kinetic_text_layer(text,dur)\n",
        "        arrow = moving_arrow(dur)\n",
        "\n",
        "        scene = CompositeVideoClip([bg,arrow,txt])\n",
        "        scene = scene.set_audio(audio.subclip(start,end))\n",
        "\n",
        "        segments.append(scene.crossfadein(0.2))\n"
      ],
      "metadata": {
        "id": "-jfDGQmkwwnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intro = TextClip(\"OPEN MEDIA UNIVERSITY\",\n",
        "                 fontsize=100,\n",
        "                 color=\"white\",\n",
        "                 font=\"DejaVu-Sans-Bold\")\\\n",
        "        .set_duration(3)\\\n",
        "        .fadein(1).fadeout(1)\\\n",
        "        .set_position(\"center\")\n",
        "\n",
        "outro = TextClip(\"SUBSCRIBE FOR NEXT EPISODE\",\n",
        "                 fontsize=80,\n",
        "                 color=\"yellow\",\n",
        "                 font=\"DejaVu-Sans-Bold\")\\\n",
        "        .set_duration(4)\\\n",
        "        .fadein(1)\\\n",
        "        .set_position(\"center\")\n"
      ],
      "metadata": {
        "id": "nkfb4ttWwyDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_video = concatenate_videoclips(\n",
        "    [intro] + segments + [outro],\n",
        "    method=\"compose\"\n",
        ")\n",
        "\n",
        "final_video.write_videofile(\"final.mp4\",fps=30)\n"
      ],
      "metadata": {
        "id": "2F-faztKw2v2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}